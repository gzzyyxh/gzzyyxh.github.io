<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>1</title>
      <link href="2021/04/20/DL-with-python-1/"/>
      <url>2021/04/20/DL-with-python-1/</url>
      
        <content type="html"><![CDATA[<p>2.1-a-first-look-at-a-neural-network</p><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> keras<br>keras.__version__<br></code></pre></td></tr></table></figure><pre><code>&#39;2.4.3&#39;</code></pre><h1 id="A-first-look-at-a-neural-network"><a href="#A-first-look-at-a-neural-network" class="headerlink" title="A first look at a neural network"></a>A first look at a neural network</h1><p>This notebook contains the code samples found in Chapter 2, Section 1 of <a href="https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff">Deep Learning with Python</a>. Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.</p><hr><p>We will now take a look at a first concrete example of a neural network, which makes use of the Python library Keras to learn to classify<br>hand-written digits. Unless you already have experience with Keras or similar libraries, you will not understand everything about this<br>first example right away. You probably haven’t even installed Keras yet. Don’t worry, that is perfectly fine. In the next chapter, we will<br>review each element in our example and explain them in detail. So don’t worry if some steps seem arbitrary or look like magic to you!<br>We’ve got to start somewhere.</p><p>The problem we are trying to solve here is to classify grayscale images of handwritten digits (28 pixels by 28 pixels), into their 10<br>categories (0 to 9). The dataset we will use is the MNIST dataset, a classic dataset in the machine learning community, which has been<br>around for almost as long as the field itself and has been very intensively studied. It’s a set of 60,000 training images, plus 10,000 test<br>images, assembled by the National Institute of Standards and Technology (the NIST in MNIST) in the 1980s. You can think of “solving” MNIST<br>as the “Hello World” of deep learning – it’s what you do to verify that your algorithms are working as expected. As you become a machine<br>learning practitioner, you will see MNIST come up over and over again, in scientific papers, blog posts, and so on.</p><p>The MNIST dataset comes pre-loaded in Keras, in the form of a set of four Numpy arrays:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> keras.datasets <span class="hljs-keyword">import</span> mnist<br><br>(train_images, train_labels), (test_images, test_labels) = mnist.load_data()<br></code></pre></td></tr></table></figure><p><code>train_images</code> and <code>train_labels</code> form the “training set”, the data that the model will learn from. The model will then be tested on the<br>“test set”, <code>test_images</code> and <code>test_labels</code>. Our images are encoded as Numpy arrays, and the labels are simply an array of digits, ranging<br>from 0 to 9. There is a one-to-one correspondence between the images and the labels.</p><p>Let’s have a look at the training data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">train_images.shape<br></code></pre></td></tr></table></figure><pre><code>(60000, 28, 28)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">len</span>(train_labels)<br></code></pre></td></tr></table></figure><pre><code>60000</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">train_labels<br></code></pre></td></tr></table></figure><pre><code>array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)</code></pre><p>Let’s have a look at the test data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">test_images.shape<br></code></pre></td></tr></table></figure><pre><code>(10000, 28, 28)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">len</span>(test_labels)<br></code></pre></td></tr></table></figure><pre><code>10000</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">test_labels<br></code></pre></td></tr></table></figure><pre><code>array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)</code></pre><p>Our workflow will be as follow: first we will present our neural network with the training data, <code>train_images</code> and <code>train_labels</code>. The<br>network will then learn to associate images and labels. Finally, we will ask the network to produce predictions for <code>test_images</code>, and we<br>will verify if these predictions match the labels from <code>test_labels</code>.</p><p>Let’s build our network – again, remember that you aren’t supposed to understand everything about this example just yet.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> keras <span class="hljs-keyword">import</span> models<br><span class="hljs-keyword">from</span> keras <span class="hljs-keyword">import</span> layers<br><br>network = models.Sequential()<br>network.add(layers.Dense(<span class="hljs-number">512</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>, input_shape=(<span class="hljs-number">28</span> * <span class="hljs-number">28</span>,)))<br>network.add(layers.Dense(<span class="hljs-number">10</span>, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>))<br></code></pre></td></tr></table></figure><p>The core building block of neural networks is the “layer”, a data-processing module which you can conceive as a “filter” for data. Some<br>data comes in, and comes out in a more useful form. Precisely, layers extract <em>representations</em> out of the data fed into them – hopefully<br>representations that are more meaningful for the problem at hand. Most of deep learning really consists of chaining together simple layers<br>which will implement a form of progressive “data distillation”. A deep learning model is like a sieve for data processing, made of a<br>succession of increasingly refined data filters – the “layers”.</p><p>Here our network consists of a sequence of two <code>Dense</code> layers, which are densely-connected (also called “fully-connected”) neural layers.<br>The second (and last) layer is a 10-way “softmax” layer, which means it will return an array of 10 probability scores (summing to 1). Each<br>score will be the probability that the current digit image belongs to one of our 10 digit classes.</p><p>To make our network ready for training, we need to pick three more things, as part of “compilation” step:</p><ul><li>A loss function: the is how the network will be able to measure how good a job it is doing on its training data, and thus how it will be<br>able to steer itself in the right direction.</li><li>An optimizer: this is the mechanism through which the network will update itself based on the data it sees and its loss function.</li><li>Metrics to monitor during training and testing. Here we will only care about accuracy (the fraction of the images that were correctly<br>classified).</li></ul><p>The exact purpose of the loss function and the optimizer will be made clear throughout the next two chapters.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">network.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&#x27;rmsprop&#x27;</span>,<br>                loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>,<br>                metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br></code></pre></td></tr></table></figure><p>Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in<br>the <code>[0, 1]</code> interval. Previously, our training images for instance were stored in an array of shape <code>(60000, 28, 28)</code> of type <code>uint8</code> with<br>values in the <code>[0, 255]</code> interval. We transform it into a <code>float32</code> array of shape <code>(60000, 28 * 28)</code> with values between 0 and 1.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">train_images = train_images.reshape((<span class="hljs-number">60000</span>, <span class="hljs-number">28</span> * <span class="hljs-number">28</span>))<br>train_images = train_images.astype(<span class="hljs-string">&#x27;float32&#x27;</span>) / <span class="hljs-number">255</span><br><br>test_images = test_images.reshape((<span class="hljs-number">10000</span>, <span class="hljs-number">28</span> * <span class="hljs-number">28</span>))<br>test_images = test_images.astype(<span class="hljs-string">&#x27;float32&#x27;</span>) / <span class="hljs-number">255</span><br></code></pre></td></tr></table></figure><p>We also need to categorically encode the labels, a step which we explain in chapter 3:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> to_categorical<br><br>train_labels = to_categorical(train_labels)<br>test_labels = to_categorical(test_labels)<br></code></pre></td></tr></table></figure><p>We are now ready to train our network, which in Keras is done via a call to the <code>fit</code> method of the network:<br>we “fit” the model to its training data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">network.fit(train_images, train_labels, epochs=<span class="hljs-number">5</span>, batch_size=<span class="hljs-number">128</span>)<br></code></pre></td></tr></table></figure><pre><code>Epoch 1/5469/469 [==============================] - 2s 5ms/step - loss: 0.0272 - accuracy: 0.9920Epoch 2/5469/469 [==============================] - 2s 5ms/step - loss: 0.0212 - accuracy: 0.9939Epoch 3/5469/469 [==============================] - 2s 5ms/step - loss: 0.0159 - accuracy: 0.9955Epoch 4/5469/469 [==============================] - 2s 4ms/step - loss: 0.0123 - accuracy: 0.9964Epoch 5/5469/469 [==============================] - 2s 4ms/step - loss: 0.0101 - accuracy: 0.9973&lt;tensorflow.python.keras.callbacks.History at 0x2bb3ae958b0&gt;</code></pre><p>Two quantities are being displayed during training: the “loss” of the network over the training data, and the accuracy of the network over<br>the training data.</p><p>We quickly reach an accuracy of 0.989 (i.e. 98.9%) on the training data. Now let’s check that our model performs well on the test set too:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">test_loss, test_acc = network.evaluate(test_images, test_labels)<br></code></pre></td></tr></table></figure><pre><code>313/313 [==============================] - 1s 3ms/step - loss: 0.0721 - accuracy: 0.9808</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;test_acc:&#x27;</span>, test_acc)<br></code></pre></td></tr></table></figure><pre><code>test_acc: 0.9807999730110168</code></pre><p>Our test set accuracy turns out to be 97.8% – that’s quite a bit lower than the training set accuracy.<br>This gap between training accuracy and test accuracy is an example of “overfitting”,<br>the fact that machine learning models tend to perform worse on new data than on their training data.<br>Overfitting will be a central topic in chapter 3.</p><p>This concludes our very first example – you just saw how we could build and a train a neural network to classify handwritten digits, in<br>less than 20 lines of Python code. In the next chapter, we will go in detail over every moving piece we just previewed, and clarify what is really<br>going on behind the scenes. You will learn about “tensors”, the data-storing objects going into the network, about tensor operations, which<br>layers are made of, and about gradient descent, which allows our network to learn from its training examples.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><br></code></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>一篇突然爆红网络的博士论文致谢</title>
      <link href="2021/04/19/%E4%B8%80%E7%AF%87%E7%AA%81%E7%84%B6%E7%88%86%E7%BA%A2%E7%BD%91%E7%BB%9C%E7%9A%84%E5%8D%9A%E5%A3%AB%E8%AE%BA%E6%96%87%E8%87%B4%E8%B0%A2/"/>
      <url>2021/04/19/%E4%B8%80%E7%AF%87%E7%AA%81%E7%84%B6%E7%88%86%E7%BA%A2%E7%BD%91%E7%BB%9C%E7%9A%84%E5%8D%9A%E5%A3%AB%E8%AE%BA%E6%96%87%E8%87%B4%E8%B0%A2/</url>
      
        <content type="html"><![CDATA[<p><img src="/img/4.19.png" alt="他的世界本无光，他把自己活成了光。"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>What&#39;s Maching Learning?</title>
      <link href="2021/04/17/What-s-Maching-Learning/"/>
      <url>2021/04/17/What-s-Maching-Learning/</url>
      
        <content type="html"><![CDATA[<p>贴上了黄博的github笔记</p><span id="more"></span><h2 id="M-D-L的一些资源"><a href="#M-D-L的一些资源" class="headerlink" title="M(D)L的一些资源"></a>M(D)L的一些资源</h2><ol><li><p>黄海广github： <a href="https://github.com/fengdu78">https://github.com/fengdu78</a></p></li><li><p>ML：笔记在线阅读： <a href="http://www.ai-start.com/ml2014/">http://www.ai-start.com/ml2014/</a></p></li><li><p>ML： github：<a href="https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes">https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes</a></p></li><li><p>DL：笔记在线阅读： <a href="http://www.ai-start.com/dl2017/">http://www.ai-start.com/dl2017/</a></p></li><li><p>DL： github： <a href="https://github.com/fengdu78/deeplearning_ai_books">https://github.com/fengdu78/deeplearning_ai_books</a></p></li><li><p>数据科学笔记：github：<a href="https://github.com/fengdu78/Data-Science-Notes">https://github.com/fengdu78/Data-Science-Notes</a></p></li><li><p>统计学习方法代码复现：github：<a href="https://github.com/wzyonggege/">https://github.com/wzyonggege/</a></p></li><li><p>statistical-learning-method or <a href="https://github.com/WenDesi/lihang_book_algorithm">https://github.com/WenDesi/lihang_book_algorithm</a></p></li><li><p>李宏毅ML教材习题解答及实现： <a href="https://github.com/Doraemonzzz/Learning-from-data">https://github.com/Doraemonzzz/Learning-from-data</a></p></li><li><p>李宏毅讲义： <a href="https://pan.baidu.com/s/1t0EpHwx46u_yzgPfpzOJyg">https://pan.baidu.com/s/1t0EpHwx46u_yzgPfpzOJyg</a> key：h74o</p></li><li><p>吴恩达有关tensorflow的介绍：对应4笔记p251</p></li><li><p>tensorflow简要介绍： <a href="https://link.zhihu.com/?target=https://github.com/aymericdamien/TensorFlow-Examples">https://link.zhihu.com/?target=https%3A//github.com/aymericdamien/TensorFlow-Examples</a></p></li><li><p>DL with python：<a href="https://github.com/fchollet/deep-learning-with-python-notebooks">https://github.com/fchollet/deep-learning-with-python-notebooks</a></p></li><li><p>pytorch入门：<a href="https://github.com/yunjey/pytorch-tutorial">https://github.com/yunjey/pytorch-tutorial</a></p></li><li><p>sql： 语法查询：<a href="http://www.w3school.com.cn/sql/index.asp">http://www.w3school.com.cn/sql/index.asp</a></p></li><li><p>sql： 语法题库：<a href="https://leetcode-cn.com/problemset/database/">https://leetcode-cn.com/problemset/database/</a></p></li><li><p>Ubuntu 18.04深度学习环境配置（CUDA9.0+CUDNN7.4+TensorFlow1.8：<a href="https://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;mid=2247484401&amp;idx=1&amp;sn=73e97612c8a8c6cbb65461f999c024ff&amp;source=41#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;mid=2247484401&amp;idx=1&amp;sn=73e97612c8a8c6cbb65461f999c024ff&amp;source=41#wechat_redirect</a></p></li><li><p>徐亦达老师课件及下载（中文目录）：<a href="https://github.com/roboticcam/machine-learning-notes">https://github.com/roboticcam/machine-learning-notes</a></p></li><li><p>华校专老师笔记： <a href="https://github.com/huaxz1986">https://github.com/huaxz1986</a></p></li><li><p>华校专网站： <a href="http://www.huaxiaozhuan.com/">http://www.huaxiaozhuan.com/</a></p></li><li><p>论文排班教程： <a href="https://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;mid=2247484392&amp;idx=1&amp;sn=6fb2fe9f619154bcbf0b6d8475e56901&amp;source=41#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;mid=2247484392&amp;idx=1&amp;sn=6fb2fe9f619154bcbf0b6d8475e56901&amp;source=41#wechat_redirect</a></p></li><li><p>zotero论文管理工具：<a href="https://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;mid=2247484429&amp;idx=1&amp;sn=5663338e5c76374512fa354d68b5a67d&amp;source=41#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;mid=2247484429&amp;idx=1&amp;sn=5663338e5c76374512fa354d68b5a67d&amp;source=41#wechat_redirect</a></p></li><li><p>tf，pytorch，keras样例资源：</p></li></ol><h2 id="一、TensorFlow"><a href="#一、TensorFlow" class="headerlink" title="一、TensorFlow"></a>一、TensorFlow</h2><h3 id="资源地址"><a href="#资源地址" class="headerlink" title="资源地址"></a>资源地址</h3><p><a href="https://github.com/aymericdamien/TensorFlow-Examples">https://github.com/aymericdamien/TensorFlow-Examples</a></p><h3 id="资源介绍"><a href="#资源介绍" class="headerlink" title="资源介绍"></a>资源介绍</h3><p>本资源旨在通过示例轻松深入了解TensorFlow。 为了便于阅读，它包括notebook和带注释的源代码。</p><p>它适合想要找到关于TensorFlow的清晰简洁示例的初学者。 除了传统的“原始”TensorFlow实现，您还可以找到最新的TensorFlow API实践（例如layers,estimator,dataset, ……）。</p><p>最后更新（07/25/2018）：添加新示例（GBDT，Word2Vec）和 TF1.9兼容性！ （TF v1.9 +推荐）。</p><h3 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h3><p>python 3.6以上，TensorFlow 1.8+</p><h3 id="资源目录"><a href="#资源目录" class="headerlink" title="资源目录"></a>资源目录</h3><h4 id="0-先决条件"><a href="#0-先决条件" class="headerlink" title="0  - 先决条件"></a>0  - 先决条件</h4><p>机器学习简介</p><p>MNIST数据集简介</p><h4 id="1-简介"><a href="#1-简介" class="headerlink" title="1  - 简介"></a>1  - 简介</h4><p>Hello World(包含notebook和py源代码)。非常简单的例子，学习如何使用TensorFlow打印“hello world”。</p><p>基本操作(包含notebook和py源代码)。一个涵盖TensorFlow基本操作的简单示例。</p><p>TensorFlow Eager API基础知识(包含notebook和py源代码)。开始使用TensorFlow的Eager API。</p><h4 id="2-基础模型"><a href="#2-基础模型" class="headerlink" title="2  - 基础模型"></a>2  - 基础模型</h4><p>线性回归(包含notebook和py源代码)。使用TensorFlow实现线性回归。</p><p>线性回归（eager api）(包含notebook和py源代码)。使用TensorFlow的Eager API实现线性回归。</p><p>Logistic回归(包含notebook和py源代码)。使用TensorFlow实现Logistic回归。</p><p>Logistic回归（eager api）(包含notebook和py源代码)。使用TensorFlow的Eager API实现Logistic回归。</p><p>最近邻(包含notebook和py源代码)。使用TensorFlow实现最近邻算法。</p><p>K-Means(包含notebook和py源代码)。使用TensorFlow构建K-Means分类器。</p><p>随机森林(包含notebook和py源代码)。使用TensorFlow构建随机森林分类器。</p><p>Gradient Boosted Decision Tree（GBDT）(包含notebook和py源代码)。使用TensorFlow构建梯度提升决策树（GBDT）。</p><p>Word2Vec（词嵌入）(包含notebook和py源代码)。使用TensorFlow从Wikipedia数据构建词嵌入模型（Word2Vec）。</p><h4 id="3-神经网络"><a href="#3-神经网络" class="headerlink" title="3  - 神经网络"></a>3  - 神经网络</h4><h5 id="监督学习部分"><a href="#监督学习部分" class="headerlink" title="监督学习部分"></a>监督学习部分</h5><p>简单神经网络(包含notebook和py源代码)。构建一个简单的神经网络（如多层感知器）来对MNIST数字数据集进行分类。 Raw TensorFlow实现。</p><p>简单神经网络（tf.layers / estimator api）(包含notebook和py源代码)。使用TensorFlow’layers’和’estimator’API构建一个简单的神经网络（如：Multi-layer Perceptron）来对MNIST数字数据集进行分类。</p><p>简单神经网络（Eager API）(包含notebook和py源代码)。使用TensorFlow Eager API构建一个简单的神经网络（如多层感知器）来对MNIST数字数据集进行分类。</p><p>卷积神经网络(包含notebook和py源代码)。构建卷积神经网络以对MNIST数字数据集进行分类。 Raw TensorFlow实现。</p><p>卷积神经网络（tf.layers / estimator api）(包含notebook和py源代码)。使用TensorFlow’layers’和’estimator’API构建卷积神经网络，对MNIST数字数据集进行分类。</p><p>递归神经网络（LSTM）(包含notebook和py源代码)。构建递归神经网络（LSTM）以对MNIST数字数据集进行分类。</p><p>双向LSTM(包含notebook和py源代码)。构建双向递归神经网络（LSTM）以对MNIST数字数据集进行分类。</p><p>动态LSTM(包含notebook和py源代码)。构建一个递归神经网络（LSTM），执行动态计算以对不同长度的序列进行分类。</p><h5 id="无监督"><a href="#无监督" class="headerlink" title="无监督"></a>无监督</h5><p>自动编码器(包含notebook和py源代码)。构建自动编码器以将图像编码为较低维度并重新构建它。</p><p>变分自动编码器（(包含notebook和py源代码)。构建变分自动编码器（VAE），对噪声进行编码和生成图像。</p><p>GAN（Generative Adversarial Networks）(包含notebook和py源代码)。构建生成对抗网络（GAN）以从噪声生成图像。</p><p>DCGAN（Deep Convolutional Generative Adversarial Networks）(包含notebook和py源代码)。构建深度卷积生成对抗网络（DCGAN）以从噪声生成图像。</p><h4 id="4-工具"><a href="#4-工具" class="headerlink" title="4  - 工具"></a>4  - 工具</h4><p>保存和还原模型(包含notebook和py源代码)。使用TensorFlow保存和还原模型。</p><p>Tensorboard  - 图形和损失可视化(包含notebook和py源代码)。使用Tensorboard可视化计算图并绘制损失。</p><p>Tensorboard  - 高级可视化(包含notebook和py源代码)。深入了解Tensorboard;可视化变量，梯度等……</p><h4 id="5-数据管理"><a href="#5-数据管理" class="headerlink" title="5  - 数据管理"></a>5  - 数据管理</h4><p>构建图像数据集(包含notebook和py源代码)。使用TensorFlow数据队列，从图像文件夹或数据集文件构建您自己的图像数据集。</p><p>TensorFlow数据集API(包含notebook和py源代码)。引入TensorFlow数据集API以优化输入数据管道。</p><h4 id="6-多GPU"><a href="#6-多GPU" class="headerlink" title="6  - 多GPU"></a>6  - 多GPU</h4><p>多GPU的基本操作(包含notebook和py源代码)。在TensorFlow中引入多GPU的简单示例。</p><p>在多GPU上训练神经网络(包含notebook和py源代码)。一个清晰简单的TensorFlow实现，用于在多个GPU上训练卷积神经网络。</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>一些示例需要MNIST数据集进行训练和测试。官方网站：<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></p><h2 id="二、Keras"><a href="#二、Keras" class="headerlink" title="二、Keras"></a>二、Keras</h2><h3 id="资源地址-1"><a href="#资源地址-1" class="headerlink" title="资源地址"></a>资源地址</h3><p><a href="https://github.com/erhwenkuo/deep-learning-with-keras-notebooks">https://github.com/erhwenkuo/deep-learning-with-keras-notebooks</a></p><h3 id="资源介绍-1"><a href="#资源介绍-1" class="headerlink" title="资源介绍"></a>资源介绍</h3><p>这个github的repository主要是ErhWen Kuo在学习Keras的一些记录及练习。希望在学习过程中发现到一些好的信息与示例也可以对想要学习使用Keras来解决问题的同学带来帮助。这些notebooks主要是使用Python 3.6与Keras 2.1.1版本跑在一台配置Nivida 1080Ti的Windows 10的机台所产生的结果，但有些部份会参杂一些Tensorflow与其它的函式库的介绍。</p><h3 id="配置环境-1"><a href="#配置环境-1" class="headerlink" title="配置环境"></a>配置环境</h3><p>python 3.6以上，Keras 2.1.1</p><h3 id="资源目录-1"><a href="#资源目录-1" class="headerlink" title="资源目录"></a>资源目录</h3><h4 id="0-图象数据集-工具介绍"><a href="#0-图象数据集-工具介绍" class="headerlink" title="0.图象数据集/工具介绍"></a>0.图象数据集/工具介绍</h4><h5 id="0-0-COCO-API解说与简单示例"><a href="#0-0-COCO-API解说与简单示例" class="headerlink" title="0.0: COCO API解说与简单示例"></a>0.0: COCO API解说与简单示例</h5><h5 id="0-1-土炮自制扑克牌图象数据集"><a href="#0-1-土炮自制扑克牌图象数据集" class="headerlink" title="0.1:土炮自制扑克牌图象数据集"></a>0.1:土炮自制扑克牌图象数据集</h5><h5 id="0-2-使用Pillow来进行图像处理"><a href="#0-2-使用Pillow来进行图像处理" class="headerlink" title="0.2:使用Pillow来进行图像处理"></a>0.2:使用Pillow来进行图像处理</h5><h4 id="1-Keras-API示例"><a href="#1-Keras-API示例" class="headerlink" title="1.Keras API示例"></a>1.Keras API示例</h4><h5 id="1-0-使用图像增强来进行深度学习"><a href="#1-0-使用图像增强来进行深度学习" class="headerlink" title="1.0:使用图像增强来进行深度学习"></a>1.0:使用图像增强来进行深度学习</h5><h5 id="1-1-如何使用Keras函数式API进行深度学习"><a href="#1-1-如何使用Keras函数式API进行深度学习" class="headerlink" title="1.1:如何使用Keras函数式API进行深度学习"></a>1.1:如何使用Keras函数式API进行深度学习</h5><h5 id="1-2-从零开始构建VGG网络来学习Keras"><a href="#1-2-从零开始构建VGG网络来学习Keras" class="headerlink" title="1.2:从零开始构建VGG网络来学习Keras"></a>1.2:从零开始构建VGG网络来学习Keras</h5><h5 id="1-3-使用预训练的模型来分类照片中的物体"><a href="#1-3-使用预训练的模型来分类照片中的物体" class="headerlink" title="1.3:使用预训练的模型来分类照片中的物体"></a>1.3:使用预训练的模型来分类照片中的物体</h5><h5 id="1-4-使用图像增强来训练小数据集"><a href="#1-4-使用图像增强来训练小数据集" class="headerlink" title="1.4:使用图像增强来训练小数据集"></a>1.4:使用图像增强来训练小数据集</h5><h5 id="1-5-使用预先训练的卷积网络模型"><a href="#1-5-使用预先训练的卷积网络模型" class="headerlink" title="1.5:使用预先训练的卷积网络模型"></a>1.5:使用预先训练的卷积网络模型</h5><h5 id="1-6-卷积网络模型学习到什么的可视化"><a href="#1-6-卷积网络模型学习到什么的可视化" class="headerlink" title="1.6:卷积网络模型学习到什么的可视化"></a>1.6:卷积网络模型学习到什么的可视化</h5><h5 id="1-7-构建自动编码器（Autoencoder）"><a href="#1-7-构建自动编码器（Autoencoder）" class="headerlink" title="1.7:构建自动编码器（Autoencoder）"></a>1.7:构建自动编码器（Autoencoder）</h5><h5 id="1-8-序列到序列（Seq-to-Seq）学习介绍"><a href="#1-8-序列到序列（Seq-to-Seq）学习介绍" class="headerlink" title="1.8:序列到序列（Seq-to-Seq）学习介绍"></a>1.8:序列到序列（Seq-to-Seq）学习介绍</h5><h5 id="1-9-One-hot编码工具程序介绍"><a href="#1-9-One-hot编码工具程序介绍" class="headerlink" title="1.9: One-hot编码工具程序介绍"></a>1.9: One-hot编码工具程序介绍</h5><h5 id="1-10-循环神经网络（RNN）介绍"><a href="#1-10-循环神经网络（RNN）介绍" class="headerlink" title="1.10:循环神经网络（RNN）介绍"></a>1.10:循环神经网络（RNN）介绍</h5><h5 id="1-11-LSTM的返回序列和返回状态之间的区别"><a href="#1-11-LSTM的返回序列和返回状态之间的区别" class="headerlink" title="1.11: LSTM的返回序列和返回状态之间的区别"></a>1.11: LSTM的返回序列和返回状态之间的区别</h5><h5 id="1-12-用LSTM来学习英文字母表顺序"><a href="#1-12-用LSTM来学习英文字母表顺序" class="headerlink" title="1.12:用LSTM来学习英文字母表顺序"></a>1.12:用LSTM来学习英文字母表顺序</h5><h4 id="2-图像分类（Image-Classification）"><a href="#2-图像分类（Image-Classification）" class="headerlink" title="2.图像分类（Image Classification）"></a>2.图像分类（Image Classification）</h4><h5 id="2-0-Julia（Chars74K）字母图像分类"><a href="#2-0-Julia（Chars74K）字母图像分类" class="headerlink" title="2.0: Julia（Chars74K）字母图像分类"></a>2.0: Julia（Chars74K）字母图像分类</h5><h5 id="2-1-交通标志图像分类"><a href="#2-1-交通标志图像分类" class="headerlink" title="2.1:交通标志图像分类"></a>2.1:交通标志图像分类</h5><h5 id="2-2-辛普森卡通图像角色分类"><a href="#2-2-辛普森卡通图像角色分类" class="headerlink" title="2.2:辛普森卡通图像角色分类"></a>2.2:辛普森卡通图像角色分类</h5><h5 id="2-3-时尚服饰图像分类"><a href="#2-3-时尚服饰图像分类" class="headerlink" title="2.3:时尚服饰图像分类"></a>2.3:时尚服饰图像分类</h5><h5 id="2-4-人脸关键点辨识"><a href="#2-4-人脸关键点辨识" class="headerlink" title="2.4:人脸关键点辨识"></a>2.4:人脸关键点辨识</h5><h5 id="2-5-Captcha验证码分类"><a href="#2-5-Captcha验证码分类" class="headerlink" title="2.5: Captcha验证码分类"></a>2.5: Captcha验证码分类</h5><h5 id="2-6-Mnist手写图像分类（MLP）"><a href="#2-6-Mnist手写图像分类（MLP）" class="headerlink" title="2.6: Mnist手写图像分类（MLP）"></a>2.6: Mnist手写图像分类（MLP）</h5><h5 id="2-7-Mnist手写图像分类（CNN）"><a href="#2-7-Mnist手写图像分类（CNN）" class="headerlink" title="2.7: Mnist手写图像分类（CNN）"></a>2.7: Mnist手写图像分类（CNN）</h5><h4 id="3-目标检测（Object-Recognition）"><a href="#3-目标检测（Object-Recognition）" class="headerlink" title="3.目标检测（Object Recognition）"></a>3.目标检测（Object Recognition）</h4><h5 id="3-0-YOLO目标检测算法概念与介绍"><a href="#3-0-YOLO目标检测算法概念与介绍" class="headerlink" title="3.0: YOLO目标检测算法概念与介绍"></a>3.0: YOLO目标检测算法概念与介绍</h5><h5 id="3-1-YOLOv2目标检测示例"><a href="#3-1-YOLOv2目标检测示例" class="headerlink" title="3.1: YOLOv2目标检测示例"></a>3.1: YOLOv2目标检测示例</h5><h5 id="3-2-浣熊（Racoon）检测-YOLOv2模型训练与调整"><a href="#3-2-浣熊（Racoon）检测-YOLOv2模型训练与调整" class="headerlink" title="3.2:浣熊（Racoon）检测-YOLOv2模型训练与调整"></a>3.2:浣熊（Racoon）检测-YOLOv2模型训练与调整</h5><h5 id="3-3-浣熊（Racoon）检测-YOLOv2模型的使用"><a href="#3-3-浣熊（Racoon）检测-YOLOv2模型的使用" class="headerlink" title="3.3:浣熊（Racoon）检测-YOLOv2模型的使用"></a>3.3:浣熊（Racoon）检测-YOLOv2模型的使用</h5><h5 id="3-4-袋鼠（Kangaroo）检测-YOLOv2模型训练与调整"><a href="#3-4-袋鼠（Kangaroo）检测-YOLOv2模型训练与调整" class="headerlink" title="3.4:袋鼠（Kangaroo）检测-YOLOv2模型训练与调整"></a>3.4:袋鼠（Kangaroo）检测-YOLOv2模型训练与调整</h5><h5 id="3-5-双手（Hands）检测-YOLOv2模型训练与调整"><a href="#3-5-双手（Hands）检测-YOLOv2模型训练与调整" class="headerlink" title="3.5:双手（Hands）检测-YOLOv2模型训练与调整"></a>3.5:双手（Hands）检测-YOLOv2模型训练与调整</h5><h5 id="3-6-辛普森卡通图象角色（Simpson）检测-YOLOv2模型训练与调整"><a href="#3-6-辛普森卡通图象角色（Simpson）检测-YOLOv2模型训练与调整" class="headerlink" title="3.6:辛普森卡通图象角色（Simpson）检测-YOLOv2模型训练与调整"></a>3.6:辛普森卡通图象角色（Simpson）检测-YOLOv2模型训练与调整</h5><h5 id="3-7-MS-COCO图象检测-YOLOv2模型训练与调整"><a href="#3-7-MS-COCO图象检测-YOLOv2模型训练与调整" class="headerlink" title="3.7: MS COCO图象检测-YOLOv2模型训练与调整"></a>3.7: MS COCO图象检测-YOLOv2模型训练与调整</h5><h4 id="4-物体分割（Object-Segmentation）"><a href="#4-物体分割（Object-Segmentation）" class="headerlink" title="4.物体分割（Object Segmentation）"></a>4.物体分割（Object Segmentation）</h4><h4 id="5-关键点检测（Keypoint-Detection）"><a href="#5-关键点检测（Keypoint-Detection）" class="headerlink" title="5.关键点检测（Keypoint Detection）"></a>5.关键点检测（Keypoint Detection）</h4><h4 id="6-图象标题（Image-Caption）"><a href="#6-图象标题（Image-Caption）" class="headerlink" title="6.图象标题（Image Caption）"></a>6.图象标题（Image Caption）</h4><h4 id="7-人脸检测识别（Face-Detection-Recognition）"><a href="#7-人脸检测识别（Face-Detection-Recognition）" class="headerlink" title="7.人脸检测识别（Face Detection/Recognition）"></a>7.人脸检测识别（Face Detection/Recognition）</h4><h5 id="7-0-人脸检测-OpenCV（Haar特征分类器）"><a href="#7-0-人脸检测-OpenCV（Haar特征分类器）" class="headerlink" title="7.0:人脸检测- OpenCV（Haar特征分类器）"></a>7.0:人脸检测- OpenCV（Haar特征分类器）</h5><h5 id="7-1-人脸检测-MTCNN（Multi-task-Cascaded-Convolutional-Networks）"><a href="#7-1-人脸检测-MTCNN（Multi-task-Cascaded-Convolutional-Networks）" class="headerlink" title="7.1:人脸检测- MTCNN（Multi-task Cascaded Convolutional Networks）"></a>7.1:人脸检测- MTCNN（Multi-task Cascaded Convolutional Networks）</h5><h5 id="7-2-人脸识别-脸部检测、对齐-amp-裁剪"><a href="#7-2-人脸识别-脸部检测、对齐-amp-裁剪" class="headerlink" title="7.2:人脸识别-脸部检测、对齐&amp;裁剪"></a>7.2:人脸识别-脸部检测、对齐&amp;裁剪</h5><h5 id="7-3-人脸识别-人脸部特征提取-amp-人脸分类器"><a href="#7-3-人脸识别-人脸部特征提取-amp-人脸分类器" class="headerlink" title="7.3:人脸识别-人脸部特征提取&amp;人脸分类器"></a>7.3:人脸识别-人脸部特征提取&amp;人脸分类器</h5><h5 id="7-4-人脸识别-转换、对齐、裁剪、特征提取与比对"><a href="#7-4-人脸识别-转换、对齐、裁剪、特征提取与比对" class="headerlink" title="7.4:人脸识别-转换、对齐、裁剪、特征提取与比对"></a>7.4:人脸识别-转换、对齐、裁剪、特征提取与比对</h5><h5 id="7-5-脸部关键点检测（dlib）"><a href="#7-5-脸部关键点检测（dlib）" class="headerlink" title="7.5:脸部关键点检测（dlib）"></a>7.5:脸部关键点检测（dlib）</h5><h5 id="7-6-头部姿态（Head-pose）估计（dlib）"><a href="#7-6-头部姿态（Head-pose）估计（dlib）" class="headerlink" title="7.6:头部姿态（Head pose）估计（dlib）"></a>7.6:头部姿态（Head pose）估计（dlib）</h5><h4 id="8-自然语言处理（Natural-Language-Processing）"><a href="#8-自然语言处理（Natural-Language-Processing）" class="headerlink" title="8.自然语言处理（Natural Language Processing）"></a>8.自然语言处理（Natural Language Processing）</h4><h5 id="8-0-词嵌入（word-embeddings）介绍"><a href="#8-0-词嵌入（word-embeddings）介绍" class="headerlink" title="8.0:词嵌入（word embeddings）介绍"></a>8.0:词嵌入（word embeddings）介绍</h5><h5 id="8-1-使用结巴（jieba）进行中文分词"><a href="#8-1-使用结巴（jieba）进行中文分词" class="headerlink" title="8.1:使用结巴（jieba）进行中文分词"></a>8.1:使用结巴（jieba）进行中文分词</h5><h5 id="8-2-Word2vec词嵌入（word-embeddings）的基本概念"><a href="#8-2-Word2vec词嵌入（word-embeddings）的基本概念" class="headerlink" title="8.2: Word2vec词嵌入（word embeddings）的基本概念"></a>8.2: Word2vec词嵌入（word embeddings）的基本概念</h5><h5 id="8-3-使用结巴（jieba）进行歌词分析"><a href="#8-3-使用结巴（jieba）进行歌词分析" class="headerlink" title="8.3:使用结巴（jieba）进行歌词分析"></a>8.3:使用结巴（jieba）进行歌词分析</h5><h5 id="8-4-使用gensim训练中文词向量（word2vec）"><a href="#8-4-使用gensim训练中文词向量（word2vec）" class="headerlink" title="8.4:使用gensim训练中文词向量（word2vec）"></a>8.4:使用gensim训练中文词向量（word2vec）</h5><h2 id="三、Pytorch"><a href="#三、Pytorch" class="headerlink" title="三、Pytorch"></a>三、Pytorch</h2><h3 id="资源地址-2"><a href="#资源地址-2" class="headerlink" title="资源地址"></a>资源地址</h3><p><a href="https://github.com/yunjey/pytorch-tutorial">https://github.com/yunjey/pytorch-tutorial</a></p><h3 id="资源介绍-2"><a href="#资源介绍-2" class="headerlink" title="资源介绍"></a>资源介绍</h3><p>这个资源为深度学习研究人员提供了学习PyTorch的教程代码大多数模型都使用少于30行代码实现。 在开始本教程之前，建议先看完Pytorch官方教程。</p><h3 id="配置环境-2"><a href="#配置环境-2" class="headerlink" title="配置环境"></a>配置环境</h3><p>python 2.7或者3.5以上，pytorch 0.4</p><h3 id="资源目录-2"><a href="#资源目录-2" class="headerlink" title="资源目录"></a>资源目录</h3><h4 id="1-基础知识"><a href="#1-基础知识" class="headerlink" title="1.基础知识"></a>1.基础知识</h4><p>PyTorch基础知识</p><p>线性回归</p><p>Logistic回归</p><p>前馈神经网络</p><h4 id="2-中级"><a href="#2-中级" class="headerlink" title="2.中级"></a>2.中级</h4><p>卷积神经网络</p><p>深度残差网络</p><p>递归神经网络</p><p>双向递归神经网络</p><p>语言模型（RNN-LM）</p><h4 id="3-高级"><a href="#3-高级" class="headerlink" title="3.高级"></a>3.高级</h4><p>生成性对抗网络</p><p>变分自动编码器</p><p>神经风格转移</p><p>图像字幕（CNN-RNN）</p><h4 id="4-工具-1"><a href="#4-工具-1" class="headerlink" title="4.工具"></a>4.工具</h4><p>PyTorch中的TensorBoard</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>my first blog</title>
      <link href="2021/04/17/my-first-blog/"/>
      <url>2021/04/17/my-first-blog/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>先发一篇试试^_^</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Test</title>
      <link href="2021/04/17/Test/"/>
      <url>2021/04/17/Test/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>A blog for test.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="2021/04/16/hello-world/"/>
      <url>2021/04/16/hello-world/</url>
      
        <content type="html"><![CDATA[<p>搞了**的整整两天，我的个人blog终于能在云端访问了^^^^</p><span id="more"></span><p>After two fucking days, Lao Tzu’s personal blog is finally online, fuck</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
